#!/usr/bin/env python3
"""
å…³é”®è¯æå–è„šæœ¬
åŠŸèƒ½ï¼šä»æ–‡æœ¬ä¸­æå–å…³é”®è¯å’Œæ ‡ç­¾
"""

import re
import os
import sys
from collections import Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class KeywordExtractor:
    """å…³é”®è¯æå–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        # åœç”¨è¯
        self.stopwords = {
            'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'ä¸', 'æˆ–', 'ä¸º', 'ç­‰', 'è¿™',
            'é‚£', 'æœ‰', 'æ²¡æœ‰', 'å¯ä»¥', 'å¦‚ä½•', 'æ€ä¹ˆ', 'ä»€ä¹ˆ',
            'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
            'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
            'would', 'could', 'should', 'may', 'might', 'must', 'shall',
            'can', 'need', 'dare', 'ought', 'used', 'to', 'of', 'in',
            'for', 'on', 'with', 'at', 'by', 'from', 'as', 'into',
            'through', 'during', 'before', 'after', 'above', 'below',
            'between', 'under', 'again', 'further', 'then', 'once',
            'here', 'there', 'when', 'where', 'why', 'how', 'all',
            'each', 'few', 'more', 'most', 'other', 'some', 'such',
            'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than',
            'too', 'very', 'just', 'also', 'now', 'this', 'that',
            'these', 'those', 'it', 'its', 'they', 'them', 'their',
            'we', 'our', 'you', 'your', 'he', 'him', 'his', 'she',
            'her', 'i', 'me', 'my', 'who', 'whom', 'which', 'what',
            'whose', 'if', 'but', 'although', 'because', 'unless',
            'while', 'about', 'against', 'over', 'throughout'
        }
        
        # å¸¸è§ç§‘æŠ€è¯æ±‡ï¼ˆä¸ä½œä¸ºå…³é”®è¯ï¼‰
        self.common_words = {
            'article', 'post', 'blog', 'news', 'update', 'release',
            'new', 'latest', 'recent', 'today', 'now', 'here',
            'read', 'learn', 'see', 'check', 'try', 'use', 'using'
        }
        
        # ä¸»é¢˜å…³é”®è¯æ˜ å°„
        self.topic_keywords = {
            'AI/æœºå™¨å­¦ä¹ ': ['ai', 'gpt', 'llm', 'machine learning', 'deep learning', 
                          'neural', 'æ¨¡å‹', 'è®­ç»ƒ', 'æ¨ç†', 'agent', 'rag', 'embeddings'],
            'ç§‘æŠ€åˆ›æŠ•': ['startup', 'funding', 'èèµ„', 'æŠ•èµ„', 'äº§å“å‘å¸ƒ', 'launch',
                       'series a', 'series b', 'ipo', 'acquisition', 'æ”¶è´­'],
            'å¼€æº': ['open source', 'github', 'å¼€æº', 'apache', 'mit license', 'ç¤¾åŒº'],
            'å¼€å‘å·¥å…·': ['framework', 'library', 'api', 'sdk', 'tool', 'å¼€å‘', 'ç¼–ç¨‹', 'ä»£ç '],
            'äº‘æœåŠ¡': ['cloud', 'aws', 'azure', 'gcp', 'serverless', 'k8s', 'docker'],
            'æ•°æ®ç§‘å­¦': ['data', 'analytics', 'å¯è§†åŒ–', 'pandas', 'spark', 'hadoop']
        }
    
    def clean_text(self, text):
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
        # è½¬å°å†™
        text = text.lower()
        # ç§»é™¤URL
        text = re.sub(r'http[s]?://\S+', '', text)
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ–‡
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = ' '.join(text.split())
        return text
    
    def extract_words(self, text):
        """æå–è¯æ±‡"""
        text = self.clean_text(text)
        words = text.split()
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        words = [
            w for w in words 
            if w not in self.stopwords 
            and w not in self.common_words
            and len(w) >= 2
        ]
        
        return words
    
    def extract_keywords(self, text, top_n=10):
        """æå–å…³é”®è¯"""
        words = self.extract_words(text)
        
        # ç»Ÿè®¡è¯é¢‘
        word_counts = Counter(words)
        
        # è·å–top_n
        keywords = word_counts.most_common(top_n)
        
        return [w for w, c in keywords]
    
    def detect_topics(self, text):
        """æ£€æµ‹ä¸»é¢˜"""
        text = self.clean_text(text)
        text_lower = text.lower()
        
        detected_topics = []
        
        for topic, keywords in self.topic_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    detected_topics.append(topic)
                    break
        
        return detected_topics if detected_topics else ['å…¶ä»–']
    
    def process_article(self, article):
        """å¤„ç†å•ç¯‡æ–‡ç« """
        text = f"{article.get('title', '')} {article.get('summary', '')} {article.get('content', '')}"
        
        return {
            'keywords': self.extract_keywords(text, top_n=8),
            'topics': self.detect_topics(text)
        }
    
    def process_batch(self, articles):
        """æ‰¹é‡å¤„ç†"""
        print(f"ğŸ” æå– {len(articles)} ç¯‡æ–‡ç« çš„å…³é”®è¯...")
        
        results = []
        all_keywords = []
        
        for i, article in enumerate(articles):
            result = self.process_article(article)
            all_keywords.extend(result['keywords'])
            results.append(result)
            
            if (i + 1) % 20 == 0:
                print(f"  å·²å¤„ç† {i + 1}/{len(articles)} ç¯‡")
        
        # ç»Ÿè®¡å…¨å±€å…³é”®è¯
        keyword_stats = Counter(all_keywords).most_common(20)
        
        print(f"  âœ… å¤„ç†å®Œæˆ")
        print(f"  ğŸ“Š å…¨å±€çƒ­é—¨å…³é”®è¯: {keyword_stats[:10]}")
        
        return results, keyword_stats


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” å…³é”®è¯æå–å™¨")
    print("=" * 60)
    
    extractor = KeywordExtractor()
    
    # æµ‹è¯•
    test_text = """
    OpenAIä»Šæ—¥å‘å¸ƒäº†GPT-4.5æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨æ¨ç†èƒ½åŠ›å’Œåˆ›æ„å†™ä½œæ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚
    è¿™æ˜¯AIé¢†åŸŸçš„é‡å¤§è¿›å±•ï¼Œæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯åˆå‘å‰è¿ˆè¿›äº†ä¸€æ­¥ã€‚
    """
    
    keywords = extractor.extract_keywords(test_text, top_n=5)
    topics = extractor.detect_topics(test_text)
    
    print(f"\næµ‹è¯•æ–‡æœ¬å…³é”®è¯: {keywords}")
    print(f"æ£€æµ‹åˆ°çš„ä¸»é¢˜: {topics}")


if __name__ == '__main__':
    main()
